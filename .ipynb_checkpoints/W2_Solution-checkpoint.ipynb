{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your name:\n",
    "\n",
    "### Collaborators:\n",
    "\n",
    "<pre> Enter the name of the people you worked with if any</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils_3253 import CategoricalEncoder\n",
    "from utils_3253 import DataFrameSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the housing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "fetch_housing_data()\n",
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Build full pipeline for the data analysis following the example of the notebook.\n",
    " Hint: the main part requested to change is the algorithm used (Lasso regression)\n",
    "\n",
    "If you want to learn more about the Lasso regression, see resources below:\n",
    "- http://scikit-learn.org/stable/modules/linear_model.html#lasso\n",
    "- https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations for building pipeline:\n",
    "\n",
    "- Split data into training and testing sets below.\n",
    "- Convert all categorical data to one-hot vectors below\n",
    "- Normalize all non-categorical data \n",
    "-  Perform Lasso-based regression using a variety of values for $\\alpha$ between 0 and 1 via a grid search where  *housing_labels* is the output and all other features are the input (similar to as seen in lecture two.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing for stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide by 1.5 to limit the number of income categories\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "# Label those above 5 as 5\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def income_cat_proportions(data):\n",
    "    return data[\"income_cat\"].value_counts() / len(data)\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": income_cat_proportions(housing),\n",
    "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
    "}).sort_index()\n",
    "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Stratified</th>\n",
       "      <th>Strat. %error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.039826</td>\n",
       "      <td>0.039729</td>\n",
       "      <td>-0.243309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.318847</td>\n",
       "      <td>0.318798</td>\n",
       "      <td>-0.015195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.350581</td>\n",
       "      <td>0.350533</td>\n",
       "      <td>-0.013820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.176357</td>\n",
       "      <td>0.027480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.114438</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.127011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall  Stratified  Strat. %error\n",
       "1.0  0.039826    0.039729      -0.243309\n",
       "2.0  0.318847    0.318798      -0.015195\n",
       "3.0  0.350581    0.350533      -0.013820\n",
       "4.0  0.176308    0.176357       0.027480\n",
       "5.0  0.114438    0.114583       0.127011"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('nrm_scaler', MinMaxScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', CategoricalEncoder(encoding=\"onehot-dense\")),\n",
    "    ])\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24501992,  0.50478215,  0.7254902 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.24103586,  0.47927736,  0.25490196, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.71215139,  0.02444208,  0.58823529, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ..., \n",
       "       [ 0.79183267,  0.16471838,  0.15686275, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.6314741 ,  0.1360255 ,  0.58823529, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.18924303,  0.55579171,  1.        , ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "housing_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full pipeline for preparation as well as Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{'alpha': [0.5,0.8,0.9, 1.0,5.0, 10.0], 'max_iter':[5000]}]\n",
    "grid_search = GridSearchCV(linear_model.Lasso(), param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benitez/anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/benitez/anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/benitez/anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preparation', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('num_pipeline', Pipeline(memory=None,\n",
       "     steps=[('selector', DataFrameSelector(attribute_names=['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income'])), ('...*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_lasso_pipeline_with_predictor = Pipeline([(\"preparation\", full_pipeline),\n",
    "        (\"lasso\", grid_search)])\n",
    "full_lasso_pipeline_with_predictor.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 10.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=10.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69133.6641407 {'alpha': 0.5}\n",
      "69125.9627212 {'alpha': 0.8}\n",
      "69123.4405753 {'alpha': 0.9}\n",
      "69121.1761625 {'alpha': 1.0}\n",
      "69065.7338444 {'alpha': 5.0}\n",
      "69027.465631 {'alpha': 10.0}\n"
     ]
    }
   ],
   "source": [
    "cvres_lasso2 = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres_lasso2[\"mean_test_score\"], cvres_lasso2[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.249627</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>-4.779464e+09</td>\n",
       "      <td>-4.702929e+09</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.475847e+09</td>\n",
       "      <td>-4.771999e+09</td>\n",
       "      <td>-5.268332e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.849860e+09</td>\n",
       "      <td>-4.679440e+09</td>\n",
       "      <td>-4.440286e+09</td>\n",
       "      <td>-4.778704e+09</td>\n",
       "      <td>-4.862937e+09</td>\n",
       "      <td>-4.684841e+09</td>\n",
       "      <td>0.016265</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>3.027160e+08</td>\n",
       "      <td>6.641619e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266107</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>-4.778399e+09</td>\n",
       "      <td>-4.702958e+09</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.475573e+09</td>\n",
       "      <td>-4.772016e+09</td>\n",
       "      <td>-5.264647e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.849594e+09</td>\n",
       "      <td>-4.679463e+09</td>\n",
       "      <td>-4.440380e+09</td>\n",
       "      <td>-4.778724e+09</td>\n",
       "      <td>-4.861743e+09</td>\n",
       "      <td>-4.684876e+09</td>\n",
       "      <td>0.020430</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>3.014819e+08</td>\n",
       "      <td>6.640612e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.264028</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>-4.778050e+09</td>\n",
       "      <td>-4.702970e+09</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 0.9}</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.475484e+09</td>\n",
       "      <td>-4.772024e+09</td>\n",
       "      <td>-5.263425e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.849509e+09</td>\n",
       "      <td>-4.679473e+09</td>\n",
       "      <td>-4.440413e+09</td>\n",
       "      <td>-4.778733e+09</td>\n",
       "      <td>-4.861364e+09</td>\n",
       "      <td>-4.684891e+09</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>3.010735e+08</td>\n",
       "      <td>6.640173e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.319577</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>-4.777737e+09</td>\n",
       "      <td>-4.702983e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.475394e+09</td>\n",
       "      <td>-4.772032e+09</td>\n",
       "      <td>-5.262369e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.849426e+09</td>\n",
       "      <td>-4.679484e+09</td>\n",
       "      <td>-4.440446e+09</td>\n",
       "      <td>-4.778742e+09</td>\n",
       "      <td>-4.860994e+09</td>\n",
       "      <td>-4.684907e+09</td>\n",
       "      <td>0.073133</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>3.007191e+08</td>\n",
       "      <td>6.639825e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.149538</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>-4.770076e+09</td>\n",
       "      <td>-4.704384e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 5.0}</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.475377e+09</td>\n",
       "      <td>-4.772928e+09</td>\n",
       "      <td>-5.230865e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.847682e+09</td>\n",
       "      <td>-4.680914e+09</td>\n",
       "      <td>-4.442363e+09</td>\n",
       "      <td>-4.779965e+09</td>\n",
       "      <td>-4.854041e+09</td>\n",
       "      <td>-4.687023e+09</td>\n",
       "      <td>0.016985</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>2.897180e+08</td>\n",
       "      <td>6.623042e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.068062</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-4.764791e+09</td>\n",
       "      <td>-4.708333e+09</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.476472e+09</td>\n",
       "      <td>-4.775146e+09</td>\n",
       "      <td>-5.191221e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.849396e+09</td>\n",
       "      <td>-4.684931e+09</td>\n",
       "      <td>-4.445823e+09</td>\n",
       "      <td>-4.783467e+09</td>\n",
       "      <td>-4.861001e+09</td>\n",
       "      <td>-4.692648e+09</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.768245e+08</td>\n",
       "      <td>6.554921e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.249627         0.000822    -4.779464e+09     -4.702929e+09   \n",
       "1       0.266107         0.000810    -4.778399e+09     -4.702958e+09   \n",
       "2       0.264028         0.000832    -4.778050e+09     -4.702970e+09   \n",
       "3       0.319577         0.000819    -4.777737e+09     -4.702983e+09   \n",
       "4       0.149538         0.000664    -4.770076e+09     -4.704384e+09   \n",
       "5       0.068062         0.000633    -4.764791e+09     -4.708333e+09   \n",
       "\n",
       "  param_alpha           params  rank_test_score  split0_test_score  \\\n",
       "0         0.5   {'alpha': 0.5}                6      -4.475847e+09   \n",
       "1         0.8   {'alpha': 0.8}                5      -4.475573e+09   \n",
       "2         0.9   {'alpha': 0.9}                4      -4.475484e+09   \n",
       "3           1   {'alpha': 1.0}                3      -4.475394e+09   \n",
       "4           5   {'alpha': 5.0}                2      -4.475377e+09   \n",
       "5          10  {'alpha': 10.0}                1      -4.476472e+09   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0       -4.771999e+09      -5.268332e+09       ...             -4.849860e+09   \n",
       "1       -4.772016e+09      -5.264647e+09       ...             -4.849594e+09   \n",
       "2       -4.772024e+09      -5.263425e+09       ...             -4.849509e+09   \n",
       "3       -4.772032e+09      -5.262369e+09       ...             -4.849426e+09   \n",
       "4       -4.772928e+09      -5.230865e+09       ...             -4.847682e+09   \n",
       "5       -4.775146e+09      -5.191221e+09       ...             -4.849396e+09   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0       -4.679440e+09      -4.440286e+09       -4.778704e+09   \n",
       "1       -4.679463e+09      -4.440380e+09       -4.778724e+09   \n",
       "2       -4.679473e+09      -4.440413e+09       -4.778733e+09   \n",
       "3       -4.679484e+09      -4.440446e+09       -4.778742e+09   \n",
       "4       -4.680914e+09      -4.442363e+09       -4.779965e+09   \n",
       "5       -4.684931e+09      -4.445823e+09       -4.783467e+09   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0      -4.862937e+09       -4.684841e+09      0.016265        0.000069   \n",
       "1      -4.861743e+09       -4.684876e+09      0.020430        0.000166   \n",
       "2      -4.861364e+09       -4.684891e+09      0.008084        0.000198   \n",
       "3      -4.860994e+09       -4.684907e+09      0.073133        0.000230   \n",
       "4      -4.854041e+09       -4.687023e+09      0.016985        0.000039   \n",
       "5      -4.861001e+09       -4.692648e+09      0.013302        0.000014   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0    3.027160e+08     6.641619e+07  \n",
       "1    3.014819e+08     6.640612e+07  \n",
       "2    3.010735e+08     6.640173e+07  \n",
       "3    3.007191e+08     6.639825e+07  \n",
       "4    2.897180e+08     6.623042e+07  \n",
       "5    2.768245e+08     6.554921e+07  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67008.079442467657"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Why is it necessary to normalize all continuous variables before performing Lasso? (OPTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 2:\n",
    "<pre> There are three reasons. In summary:\n",
    "1) Interpretability of coefficients.\n",
    "2) Ability to rank the coefficient importance by the relative magnitude of post-shrinkage coefficient estimates.\n",
    "3) No need for intercept.\n",
    "They can be explained as follows:\n",
    "Lasso regression puts constraints on the size of the coefficients associated to each variable. However, this value will depend on the magnitude of each variable. It is therefore necessary to center and reduce, or standardize, the variables.\n",
    "The result of centering the variables means that there is no longer an intercept. </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:  Conclusions\n",
    "For what values of $\\alpha$ does Lasso perform best? Does it perform as well on the housing data as the linear regressor from the lectures? Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 3:\n",
    "<pre> Lasso is performing best at α of 1 (assignment asked to check it maximum upto 1).\n",
    "It doesnt perform better than Linear regression because primarily Lasso is a regularization (simplification) method. So it works better when there are large number of festures. In the given case, number of features is 15 and hence it is not working better than LR. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:  Read appending B\n",
    "\n",
    "- Reflect on your last data project, read appendix B. Then, write down a few of the checklist items that your last data project could have used. If you have not yet done a data project, then write down a few of the items that you found most interesting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 4:\n",
    "<pre>Your own answer </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your notebook\n",
    "\n",
    "Submit your solution here\n",
    "https://goo.gl/forms/VKD7Zwu54oHjutDc2\n",
    "Make sure you rename your notebook to    \n",
    "W2_UTORid.ipynb    \n",
    "Example W2_adfasd01.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
